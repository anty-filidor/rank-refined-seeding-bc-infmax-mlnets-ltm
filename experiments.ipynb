{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doodles and notes - nothing important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import network_diffusion as nd\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1 = nx.Graph(\n",
    "    (\n",
    "        [1, 4], [2, 4], [2, 3], [3, 4], [3, 5],\n",
    "        [3, 6], [4, 5], [7, 9], [8, 9], [8, 10]\n",
    "    )\n",
    ")\n",
    "\n",
    "layer_2 = nx.Graph(\n",
    "    (\n",
    "        [1, 2], [2, 7], [2, 11], [4, 5], [4, 6],\n",
    "        [5, 11], [6, 10], [7, 9], [8, 9], [8, 10],\n",
    "        [10, 11]\n",
    "    )\n",
    ")\n",
    "\n",
    "layer_3 = nx.Graph(\n",
    "    (\n",
    "        [1, 4], [2, 6], [2, 9], [3, 4], [3, 5],\n",
    "        [4, 5], [5, 6], [5, 11], [6, 9], [7, 9], [10, 11],\n",
    "    )\n",
    ")\n",
    "\n",
    "net = nd.MultilayerNetwork.from_nx_layers([layer_1, layer_2, layer_3], [\"l1\", \"l2\", \"l3\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neighbourhood size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from misc.loader import *\n",
    "from network_diffusion.mln.mlnetwork import MLNetworkActor, MultilayerNetwork\n",
    "\n",
    "ns = nd.mln.functions.neighbourhood_size\n",
    "nsh = nd.mln.functions._ns_helper\n",
    "\n",
    "def ns_old(net: MultilayerNetwork) -> Dict[MLNetworkActor, int]:\n",
    "    \"\"\"Return neighbourhood sizes of all actors from the network.\"\"\"\n",
    "    neighbourhood_sizes: Dict[MLNetworkActor, int] = {}\n",
    "    for actor in net.get_actors():\n",
    "        a_neighbours: Set[Any] = set()\n",
    "        for l_name in actor.layers:\n",
    "            a_neighbours = a_neighbours.union(\n",
    "                set(net.layers[l_name].adj[actor.actor_id].keys())\n",
    "            )\n",
    "        neighbourhood_sizes[actor] = len(a_neighbours)\n",
    "    return neighbourhood_sizes\n",
    "\n",
    "nets = [\n",
    "    net,\n",
    "    get_aucs_network(), \n",
    "    get_ckm_physicians_network(),\n",
    "    get_eu_transportation_network(),\n",
    "    get_lazega_network(),\n",
    "    get_er2_network(),\n",
    "    get_er3_network(),\n",
    "    get_er5_network(),\n",
    "    get_sf2_network(),\n",
    "    get_sf3_network(),\n",
    "    get_sf5_network(),\n",
    "]\n",
    "\n",
    "def ravel_rank(rank):\n",
    "    return {a.actor_id: v for a, v in rank.items()}\n",
    "\n",
    "for n in nets:\n",
    "    print(ravel_rank(ns(net, 1)) == ravel_rank(ns_old(net)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-shell for single layer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "g = nx.Graph()\n",
    "g.add_edges_from(\n",
    "    [(1, 2), (1, 9), (3, 13), (4, 6),\n",
    "    (5, 6), (5, 7), (5, 8), (5, 9),\n",
    "    (5, 10), (5, 11), (5, 12), (10, 12),\n",
    "    (10, 13), (11, 14), (12, 14),\n",
    "    (12, 15), (13, 14), (13, 15),\n",
    "    (13, 17), (14, 15), (15, 16)]\n",
    ")\n",
    "nx.draw(g, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg = nx.core.k_shell(g, 2)\n",
    "nx.draw(gg, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nd.MultilayerNetwork.load_mlx(file_path=\"data/aucs.mpx\")\n",
    "fb = net.layers[\"facebook\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg = fb.copy()\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3)\n",
    "row = -1\n",
    "col = -1\n",
    "\n",
    "for k in range(9):\n",
    "\n",
    "    row += 1\n",
    "    if row % 3 == 0:\n",
    "        row = 0\n",
    "        col += 1\n",
    "\n",
    "    axis = axes[col][row]\n",
    "    axis.set_title(f\"K={k}\")\n",
    "\n",
    "    ggg = nx.k_shell(gg, k=k)\n",
    "    \n",
    "    nx.draw(ggg, with_labels=True, ax=axis)\n",
    "    print(k, [[node, nx.degree(gg, node)] for node in ggg.nodes()])\n",
    "\n",
    "    if len(list(gg.nodes())) == 0:\n",
    "        break\n",
    "\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(sh:=nx.k_shell(fb), with_labels=True)\n",
    "print(k, [[node, nx.degree(fb, node)] for node in sh.nodes()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(fb, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_k_shell_list(g: nx.Graph):\n",
    "    ksh_deepest_nodes = set(nx.k_shell(g).nodes())\n",
    "    shell_ranking = {}\n",
    "    k = 0\n",
    "\n",
    "    while True:\n",
    "        ksh_nodes = set(nx.k_shell(g, k=k).nodes())\n",
    "        shell_ranking[k] = ksh_nodes\n",
    "        if ksh_nodes == ksh_deepest_nodes:\n",
    "            break\n",
    "        k += 1\n",
    "    \n",
    "    return shell_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl = create_k_shell_list(fb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(rl)[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = [list(rl[k]) for k in sorted(rl)[::-1]]\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lll = [n for cohort in sorted(rl)[::-1] for n in rl[cohort]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lll"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Degree centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net.get_actors_num())\n",
    "for actor in net.get_actors():\n",
    "    print(actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = nd.seeding.PageRankSeedSelector()\n",
    "ranking = selector(net, actorwise=True)\n",
    "print([r.actor_id for r in ranking])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.pagerank(net.layers[\"l1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = { 'num6': 6, \"34\": 2, 'num2': 2, 'num4': 4, 'num1': 1, 'num5': 5}\n",
    "sortedDict = sorted(my_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeding_budgets = np.arange(0, 101, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [(a, 100 - a) for a in np.arange(0, 101, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.logspace(-2, 0, num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-shell for multi layer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network_diffusion.mln.functions import k_shell_mln, degree, neighbourhood_size\n",
    "\n",
    "net ## net from degree centrality\n",
    "degrees = degree(net)\n",
    "sorted(\n",
    "        [*degrees.keys()],\n",
    "        key=lambda x: degree(net)[x],\n",
    "        reverse=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbourhood_size(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "net.layers[\"l1\"].nodes[5][\"status\"] = \"test\"\n",
    "k_net = k_shell_mln(net)\n",
    "print(degree(k_net))\n",
    "print(k_net.layers[\"l1\"].nodes[5][\"status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksh_deepest_nodes = set(k_shell_mln(net).get_actors())\n",
    "shell_ranking = {}\n",
    "k = 0\n",
    "\n",
    "# iterate until deepest shell is achieved\n",
    "while True:\n",
    "\n",
    "    # compute k-shell cohort\n",
    "    ksh_nodes = k_shell_mln(net, k=k).get_actors()\n",
    "\n",
    "    # sort it according to degree in the graph\n",
    "    shell_ranking[k] = sorted(\n",
    "        ksh_nodes,\n",
    "        key=lambda x: degree(net)[x],\n",
    "        reverse=True,\n",
    "    )\n",
    "\n",
    "    # if the deepest shell is reached breake, othrwise increase k\n",
    "    if set(ksh_nodes) == ksh_deepest_nodes:\n",
    "        break\n",
    "    k += 1\n",
    "\n",
    "shell_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksh_selector = nd.seeding.KShellSeedSelector()\n",
    "ksh_selector.actorwise(net)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pagerank for MLNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_net = net.layers[\"l1\"]\n",
    "nx.pagerank(l1_net)\n",
    "\n",
    "squeezed_net = nd.mln.functions.squeeze_by_neighbourhood(net)\n",
    "raw_dict = nx.pagerank(squeezed_net)\n",
    "sorted_dict = sorted(\n",
    "    raw_dict, key=lambda x: raw_dict[x], reverse=True\n",
    ")\n",
    "\n",
    "# for k, v in raw_dict.items():\n",
    "#     print(k.actor_id, v)\n",
    "print(sorted_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd.seeding.PageRankMLNSeedSelector().actorwise(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loader import get_sf2_network\n",
    "sf2 = get_sf2_network()\n",
    "net_len = sf2.get_actors_num()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_len = len(nd.seeding.PageRankMLNSeedSelector().actorwise(sf2))\n",
    "sqnet_len = len(nd.mln.functions.squeeze_by_neighbourhood(sf2))\n",
    "print(net_len, sqnet_len, rank_len)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voterank for MLNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network_diffusion.mln.functions import voterank_actorwise\n",
    "from network_diffusion.mln.actor import MLNetworkActor\n",
    "\n",
    "# [[*l_graph.edges()] for l_graph in net.layers.values()]\n",
    "\n",
    "for _, nbr in net.layers[\"l1\"].edges(1):\n",
    "    print(_, nbr)\n",
    "    # vote_rank[nbr][1] -= 1 / avgDegree\n",
    "    # vote_rank[nbr][1] = max(vote_rank[nbr][1], 0)\n",
    "\n",
    "# n2 = nd.MultilayerNetwork.from_nx_layer(net.layers[\"l3\"].copy(), layer_names=[\"A\", \"B\", \"C\"])\n",
    "\n",
    "# net.is_directed()\n",
    "# print(voterank_actorwise(n2))\n",
    "print(voterank_actorwise(net))\n",
    "# print(nx.voterank(n2.layers[\"C\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, b in net.get_links(10):\n",
    "    print(f\"a: {a.actor_id}, b: {b.actor_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd.seeding.VoteRankMLNSeedSelector().actorwise(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reading from .edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ckm_network(path):\n",
    "    df = pd.read_csv(path, names=[\"node_1\", \"node_2\", \"layer\"])\n",
    "    net_dict = {l_name: nx.Graph() for l_name in [*df[\"layer\"].unique()]}\n",
    "    for _, row in df.iterrows():\n",
    "        net_dict[row[\"layer\"]].add_edge(row[\"node_1\"], row[\"node_2\"])\n",
    "    return nd.MultilayerNetwork.load_layers_nx(\n",
    "        layer_names=[*net_dict.keys()], network_list=[*net_dict.values()]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckm = \"data/CKM-Physicians-Innovation_4NoNature.edges\"\n",
    "eu_transportation = \"data/EUAirTransportation_multiplex_4NoNature.edges\"\n",
    "lazega = \"data/Lazega-Law-Firm_4NoNatureNoLoops.edges\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = get_ckm_network(lazega)\n",
    "print(net.get_actors_num())\n",
    "print(_ := net.get_nodes_num(), sum(_.values()), len(set(_.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aucs_network(file_path):\n",
    "    return nd.MultilayerNetwork.load_mlx(file_path)\n",
    "\n",
    "net = get_aucs_network(file_path=\"data/erererererNoLoops.mpx\")\n",
    "print(net.get_actors_num())\n",
    "print(_ := net.get_nodes_num(), sum(_.values()), len(set(_.keys())), sum([l.number_of_edges() for l in net.layers.values()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classical metrics aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking = nd.seeding.VoteRankSeedSelector().nodewise(net=net)\n",
    "\n",
    "print(ranking)\n",
    "print({l_name: len(l_graph) for l_name, l_graph in net.layers.items()})\n",
    "\n",
    "aggregated_ranking = nd.seeding.VoteRankSeedSelector().actorwise(net=net)\n",
    "\n",
    "print(aggregated_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ltm-seeding-mln",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "370e4dcd90c6b278f2eaed32c70bf26cf961be4169d33535105c1f563db5caee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
