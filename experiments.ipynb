{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doodles and notes - nothing important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import network_diffusion as nd\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1 = nx.Graph(\n",
    "    (\n",
    "        [1, 4], [2, 4], [2, 3], [3, 4], [3, 5],\n",
    "        [3, 6], [4, 5], [7, 9], [8, 9], [8, 10]\n",
    "    )\n",
    ")\n",
    "\n",
    "layer_2 = nx.Graph(\n",
    "    (\n",
    "        [1, 2], [2, 7], [2, 11], [4, 5], [4, 6],\n",
    "        [5, 11], [6, 10], [7, 9], [8, 9], [8, 10],\n",
    "        [10, 11]\n",
    "    )\n",
    ")\n",
    "\n",
    "layer_3 = nx.Graph(\n",
    "    (\n",
    "        [1, 4], [2, 6], [2, 9], [3, 4], [3, 5],\n",
    "        [4, 5], [5, 6], [5, 11], [6, 9], [7, 9], [10, 11],\n",
    "    )\n",
    ")\n",
    "\n",
    "net = nd.MultilayerNetwork.from_nx_layers(\n",
    "    [layer_1, layer_2, layer_3], [\"l1\", \"l2\", \"l3\"]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example rankings for toy network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'deg-c': {4: 1, 5: 2, 2: 3, 9: 4, 3: 5, 6: 6, 10: 7, 11: 8, 7: 9, 8: 10, 1: 11}, 'k-sh': {3: 1, 4: 2, 2: 3, 11: 4, 5: 5, 8: 6, 9: 7, 6: 8, 10: 9, 7: 10, 1: 11}, 'k-sh-m': {4: 1, 5: 2, 2: 3, 3: 4, 6: 5, 9: 6, 10: 7, 11: 8, 7: 9, 8: 10, 1: 11}, 'nghb-1s': {2: 1, 6: 2, 4: 3, 3: 4, 5: 5, 9: 6, 10: 7, 11: 8, 1: 9, 7: 10, 8: 11}, 'nghb-2s': {2: 1, 6: 2, 9: 3, 11: 4, 4: 5, 3: 6, 1: 7, 5: 8, 7: 9, 10: 10, 8: 11}, 'p-rnk': {11: 1, 3: 2, 4: 3, 9: 4, 8: 5, 2: 6, 5: 7, 10: 8, 7: 9, 6: 10, 1: 11}, 'p-rnk-m': {2: 1, 6: 2, 4: 3, 9: 4, 5: 5, 3: 6, 10: 7, 11: 8, 8: 9, 7: 10, 1: 11}, 'v-rnk': {4: 1, 9: 2, 11: 3, 3: 4, 8: 5, 2: 6, 5: 7, 1: 8, 6: 9, 10: 10, 7: 11}, 'v-rnk-m': {2: 1, 6: 2, 10: 3, 9: 4, 4: 5, 5: 6, 11: 7, 1: 8, 3: 9, 8: 10, 7: 11}}\n"
     ]
    }
   ],
   "source": [
    "rankings = {}\n",
    "\n",
    "all_selectors = {\n",
    "    \"deg-c\": nd.seeding.DegreeCentralitySelector(),\n",
    "    \"k-sh\": nd.seeding.KShellSeedSelector(),\n",
    "    \"k-sh-m\": nd.seeding.KShellMLNSeedSelector(),\n",
    "    \"nghb-1s\": nd.seeding.NeighbourhoodSizeSelector(1),\n",
    "    \"nghb-2s\": nd.seeding.NeighbourhoodSizeSelector(2),\n",
    "    \"p-rnk\": nd.seeding.PageRankSeedSelector(),\n",
    "    \"p-rnk-m\": nd.seeding.PageRankMLNSeedSelector(),\n",
    "    \"v-rnk\": nd.seeding.VoteRankSeedSelector(),\n",
    "    \"v-rnk-m\": nd.seeding.VoteRankMLNSeedSelector(),\n",
    "}\n",
    "\n",
    "for s_name, ss in all_selectors.items():\n",
    "    _ranking = ss.actorwise(net)\n",
    "    ranking = {actor.actor_id: place for place, actor in enumerate(_ranking, 1)}\n",
    "\n",
    "    if rankings.get(s_name) is None:\n",
    "        rankings[s_name] = {}\n",
    "    rankings[s_name] = ranking\n",
    "\n",
    "print(rankings)\n",
    "ranking_full = pd.DataFrame(rankings)\n",
    "ranking_full.to_csv(\"data/findings/toy_network_rank.csv\")\n",
    "\n",
    "# blablabla - it's invalid code\n",
    "# degree centrality\n",
    "# _ranking = nd.seeding.DegreeCentralitySelector().actorwise(net)\n",
    "# ranking = {actor.actor_id: place for place, actor in enumerate(_ranking, 1)}\n",
    "# score = {k.actor_id:v for k, v in degree(net).items()}\n",
    "\n",
    "# k-shell, (amend output of node_to_actor_ranking)\n",
    "# _ranking, _score = nd.seeding.KShellSeedSelector().actorwise(net) \n",
    "# ranking = {actor.actor_id: place for place, actor in enumerate(_ranking, 1)}\n",
    "# score = {k.actor_id: v for k, v in _score.items()}\n",
    "\n",
    "# k-shell-mln (amoend actorwise to return also shell_ranking)\n",
    "# _ranking, _score = nd.seeding.KShellMLNSeedSelector().actorwise(net)\n",
    "# ranking = {actor.actor_id: place for place, actor in enumerate(_ranking, 1)}\n",
    "# score = {actor.actor_id: cohort for cohort, act_list in _score.items() for actor in act_list}\n",
    "\n",
    "# neighbourhood size 1 hop (no changes in ND needed)\n",
    "# _ranking = nd.seeding.NeighbourhoodSizeSelector(connection_hop=1).actorwise(net)\n",
    "# ranking = {actor.actor_id: place for place, actor in enumerate(_ranking, 1)}\n",
    "# score = {actor.actor_id: a_nsize for actor, a_nsize in neighbourhood_size(net, 1).items()}\n",
    "\n",
    "# neighbourhood size 2 hop (no changes in ND needed)\n",
    "# _ranking = nd.seeding.NeighbourhoodSizeSelector(connection_hop=2).actorwise(net)\n",
    "# ranking = {actor.actor_id: place for place, actor in enumerate(_ranking, 1)}\n",
    "# score = {actor.actor_id: a_nsize for actor, a_nsize in neighbourhood_size(net, 2).items()}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA of networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layers</th>\n",
       "      <th>actors</th>\n",
       "      <th>nodes</th>\n",
       "      <th>edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aucs</th>\n",
       "      <td>5</td>\n",
       "      <td>61</td>\n",
       "      <td>224</td>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ckm_physicians</th>\n",
       "      <td>3</td>\n",
       "      <td>241</td>\n",
       "      <td>674</td>\n",
       "      <td>1370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eu_transportation</th>\n",
       "      <td>37</td>\n",
       "      <td>417</td>\n",
       "      <td>2034</td>\n",
       "      <td>3588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eu_trans_1</th>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lazega</th>\n",
       "      <td>3</td>\n",
       "      <td>71</td>\n",
       "      <td>212</td>\n",
       "      <td>1659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>er1</th>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>2969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>er2</th>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>2000</td>\n",
       "      <td>5459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>er3</th>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>3000</td>\n",
       "      <td>7136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>er5</th>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>15109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sf1</th>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>2786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sf2</th>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>2000</td>\n",
       "      <td>4223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sf3</th>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>3000</td>\n",
       "      <td>5010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sf5</th>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>10181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   layers  actors  nodes  edges\n",
       "aucs                    5      61    224    620\n",
       "ckm_physicians          3     241    674   1370\n",
       "eu_transportation      37     417   2034   3588\n",
       "eu_trans_1              1      63     63     62\n",
       "lazega                  3      71    212   1659\n",
       "er1                     1    1000   1000   2969\n",
       "er2                     2    1000   2000   5459\n",
       "er3                     3    1000   3000   7136\n",
       "er5                     5    1000   5000  15109\n",
       "sf1                     1    1000   1000   2786\n",
       "sf2                     2    1000   2000   4223\n",
       "sf3                     3    1000   3000   5010\n",
       "sf5                     5    1000   5000  10181"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from misc.net_loader import load_network\n",
    "nets = [\n",
    "    \"aucs\",\n",
    "    \"ckm_physicians\",\n",
    "    \"eu_transportation\",\n",
    "    \"eu_trans_1\",\n",
    "    \"lazega\",\n",
    "    \"er1\",\n",
    "    \"er2\",\n",
    "    \"er3\",\n",
    "    \"er5\",\n",
    "    \"sf1\",\n",
    "    \"sf2\",\n",
    "    \"sf3\",\n",
    "    \"sf5\",\n",
    "]\n",
    "\n",
    "stats = {}\n",
    "\n",
    "for net in nets:\n",
    "    n = load_network(net)\n",
    "    layers_cnt = len(n.get_layer_names())\n",
    "    actors_cnt = n.get_actors_num()\n",
    "    nodes_cnt = sum(n.get_nodes_num().values())\n",
    "    edges_cnt = sum([len(lg.edges()) for lg in n.layers.values()])\n",
    "    stats[net] = {\"layers\": layers_cnt, \"actors\": actors_cnt, \"nodes\": nodes_cnt, \"edges\": edges_cnt}\n",
    "\n",
    "stats = pd.DataFrame(stats).T\n",
    "stats.to_csv(\"data/findings/networks_eda.csv\")\n",
    "stats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neighbourhood size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from misc.loader import *\n",
    "from network_diffusion.mln.mlnetwork import MLNetworkActor, MultilayerNetwork\n",
    "\n",
    "ns = nd.mln.functions.neighbourhood_size\n",
    "nsh = nd.mln.functions._ns_helper\n",
    "\n",
    "def ns_old(net: MultilayerNetwork) -> Dict[MLNetworkActor, int]:\n",
    "    \"\"\"Return neighbourhood sizes of all actors from the network.\"\"\"\n",
    "    neighbourhood_sizes: Dict[MLNetworkActor, int] = {}\n",
    "    for actor in net.get_actors():\n",
    "        a_neighbours: Set[Any] = set()\n",
    "        for l_name in actor.layers:\n",
    "            a_neighbours = a_neighbours.union(\n",
    "                set(net.layers[l_name].adj[actor.actor_id].keys())\n",
    "            )\n",
    "        neighbourhood_sizes[actor] = len(a_neighbours)\n",
    "    return neighbourhood_sizes\n",
    "\n",
    "nets = [\n",
    "    net,\n",
    "    get_aucs_network(), \n",
    "    get_ckm_physicians_network(),\n",
    "    get_eu_transportation_network(),\n",
    "    get_lazega_network(),\n",
    "    get_er2_network(),\n",
    "    get_er3_network(),\n",
    "    get_er5_network(),\n",
    "    get_sf2_network(),\n",
    "    get_sf3_network(),\n",
    "    get_sf5_network(),\n",
    "]\n",
    "\n",
    "def ravel_rank(rank):\n",
    "    return {a.actor_id: v for a, v in rank.items()}\n",
    "\n",
    "for n in nets:\n",
    "    print(ravel_rank(ns(net, 1)) == ravel_rank(ns_old(net)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-shell for single layer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "g = nx.Graph()\n",
    "g.add_edges_from(\n",
    "    [(1, 2), (1, 9), (3, 13), (4, 6),\n",
    "    (5, 6), (5, 7), (5, 8), (5, 9),\n",
    "    (5, 10), (5, 11), (5, 12), (10, 12),\n",
    "    (10, 13), (11, 14), (12, 14),\n",
    "    (12, 15), (13, 14), (13, 15),\n",
    "    (13, 17), (14, 15), (15, 16)]\n",
    ")\n",
    "nx.draw(g, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg = nx.core.k_shell(g, 2)\n",
    "nx.draw(gg, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nd.MultilayerNetwork.load_mlx(file_path=\"data/aucs.mpx\")\n",
    "fb = net.layers[\"facebook\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg = fb.copy()\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3)\n",
    "row = -1\n",
    "col = -1\n",
    "\n",
    "for k in range(9):\n",
    "\n",
    "    row += 1\n",
    "    if row % 3 == 0:\n",
    "        row = 0\n",
    "        col += 1\n",
    "\n",
    "    axis = axes[col][row]\n",
    "    axis.set_title(f\"K={k}\")\n",
    "\n",
    "    ggg = nx.k_shell(gg, k=k)\n",
    "    \n",
    "    nx.draw(ggg, with_labels=True, ax=axis)\n",
    "    print(k, [[node, nx.degree(gg, node)] for node in ggg.nodes()])\n",
    "\n",
    "    if len(list(gg.nodes())) == 0:\n",
    "        break\n",
    "\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(sh:=nx.k_shell(fb), with_labels=True)\n",
    "print(k, [[node, nx.degree(fb, node)] for node in sh.nodes()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(fb, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_k_shell_list(g: nx.Graph):\n",
    "    ksh_deepest_nodes = set(nx.k_shell(g).nodes())\n",
    "    shell_ranking = {}\n",
    "    k = 0\n",
    "\n",
    "    while True:\n",
    "        ksh_nodes = set(nx.k_shell(g, k=k).nodes())\n",
    "        shell_ranking[k] = ksh_nodes\n",
    "        if ksh_nodes == ksh_deepest_nodes:\n",
    "            break\n",
    "        k += 1\n",
    "    \n",
    "    return shell_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl = create_k_shell_list(fb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(rl)[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = [list(rl[k]) for k in sorted(rl)[::-1]]\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lll = [n for cohort in sorted(rl)[::-1] for n in rl[cohort]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lll"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Degree centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net.get_actors_num())\n",
    "for actor in net.get_actors():\n",
    "    print(actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = nd.seeding.PageRankSeedSelector()\n",
    "ranking = selector(net, actorwise=True)\n",
    "print([r.actor_id for r in ranking])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.pagerank(net.layers[\"l1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = { 'num6': 6, \"34\": 2, 'num2': 2, 'num4': 4, 'num1': 1, 'num5': 5}\n",
    "sortedDict = sorted(my_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeding_budgets = np.arange(0, 101, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [(a, 100 - a) for a in np.arange(0, 101, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.logspace(-2, 0, num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-shell for multi layer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network_diffusion.mln.functions import k_shell_mln, degree, neighbourhood_size\n",
    "\n",
    "net ## net from degree centrality\n",
    "degrees = degree(net)\n",
    "sorted(\n",
    "        [*degrees.keys()],\n",
    "        key=lambda x: degree(net)[x],\n",
    "        reverse=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbourhood_size(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "net.layers[\"l1\"].nodes[5][\"status\"] = \"test\"\n",
    "k_net = k_shell_mln(net)\n",
    "print(degree(k_net))\n",
    "print(k_net.layers[\"l1\"].nodes[5][\"status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksh_deepest_nodes = set(k_shell_mln(net).get_actors())\n",
    "shell_ranking = {}\n",
    "k = 0\n",
    "\n",
    "# iterate until deepest shell is achieved\n",
    "while True:\n",
    "\n",
    "    # compute k-shell cohort\n",
    "    ksh_nodes = k_shell_mln(net, k=k).get_actors()\n",
    "\n",
    "    # sort it according to degree in the graph\n",
    "    shell_ranking[k] = sorted(\n",
    "        ksh_nodes,\n",
    "        key=lambda x: degree(net)[x],\n",
    "        reverse=True,\n",
    "    )\n",
    "\n",
    "    # if the deepest shell is reached breake, othrwise increase k\n",
    "    if set(ksh_nodes) == ksh_deepest_nodes:\n",
    "        break\n",
    "    k += 1\n",
    "\n",
    "shell_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksh_selector = nd.seeding.KShellSeedSelector()\n",
    "ksh_selector.actorwise(net)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pagerank for MLNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_net = net.layers[\"l1\"]\n",
    "nx.pagerank(l1_net)\n",
    "\n",
    "squeezed_net = nd.mln.functions.squeeze_by_neighbourhood(net)\n",
    "raw_dict = nx.pagerank(squeezed_net)\n",
    "sorted_dict = sorted(\n",
    "    raw_dict, key=lambda x: raw_dict[x], reverse=True\n",
    ")\n",
    "\n",
    "# for k, v in raw_dict.items():\n",
    "#     print(k.actor_id, v)\n",
    "print(sorted_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd.seeding.PageRankMLNSeedSelector().actorwise(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loader import get_sf2_network\n",
    "sf2 = get_sf2_network()\n",
    "net_len = sf2.get_actors_num()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_len = len(nd.seeding.PageRankMLNSeedSelector().actorwise(sf2))\n",
    "sqnet_len = len(nd.mln.functions.squeeze_by_neighbourhood(sf2))\n",
    "print(net_len, sqnet_len, rank_len)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voterank for MLNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network_diffusion.mln.functions import voterank_actorwise\n",
    "from network_diffusion.mln.actor import MLNetworkActor\n",
    "\n",
    "# [[*l_graph.edges()] for l_graph in net.layers.values()]\n",
    "\n",
    "for _, nbr in net.layers[\"l1\"].edges(1):\n",
    "    print(_, nbr)\n",
    "    # vote_rank[nbr][1] -= 1 / avgDegree\n",
    "    # vote_rank[nbr][1] = max(vote_rank[nbr][1], 0)\n",
    "\n",
    "# n2 = nd.MultilayerNetwork.from_nx_layer(net.layers[\"l3\"].copy(), layer_names=[\"A\", \"B\", \"C\"])\n",
    "\n",
    "# net.is_directed()\n",
    "# print(voterank_actorwise(n2))\n",
    "print(voterank_actorwise(net))\n",
    "# print(nx.voterank(n2.layers[\"C\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, b in net.get_links(10):\n",
    "    print(f\"a: {a.actor_id}, b: {b.actor_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd.seeding.VoteRankMLNSeedSelector().actorwise(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reading from .edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ckm_network(path):\n",
    "    df = pd.read_csv(path, names=[\"node_1\", \"node_2\", \"layer\"])\n",
    "    net_dict = {l_name: nx.Graph() for l_name in [*df[\"layer\"].unique()]}\n",
    "    for _, row in df.iterrows():\n",
    "        net_dict[row[\"layer\"]].add_edge(row[\"node_1\"], row[\"node_2\"])\n",
    "    return nd.MultilayerNetwork.load_layers_nx(\n",
    "        layer_names=[*net_dict.keys()], network_list=[*net_dict.values()]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckm = \"data/CKM-Physicians-Innovation_4NoNature.edges\"\n",
    "eu_transportation = \"data/EUAirTransportation_multiplex_4NoNature.edges\"\n",
    "lazega = \"data/Lazega-Law-Firm_4NoNatureNoLoops.edges\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = get_ckm_network(lazega)\n",
    "print(net.get_actors_num())\n",
    "print(_ := net.get_nodes_num(), sum(_.values()), len(set(_.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aucs_network(file_path):\n",
    "    return nd.MultilayerNetwork.load_mlx(file_path)\n",
    "\n",
    "net = get_aucs_network(file_path=\"data/erererererNoLoops.mpx\")\n",
    "print(net.get_actors_num())\n",
    "print(_ := net.get_nodes_num(), sum(_.values()), len(set(_.keys())), sum([l.number_of_edges() for l in net.layers.values()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classical metrics aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking = nd.seeding.VoteRankSeedSelector().nodewise(net=net)\n",
    "\n",
    "print(ranking)\n",
    "print({l_name: len(l_graph) for l_name, l_graph in net.layers.items()})\n",
    "\n",
    "aggregated_ranking = nd.seeding.VoteRankSeedSelector().actorwise(net=net)\n",
    "\n",
    "print(aggregated_ranking)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting baseline networks with one layer\n",
    "\n",
    "After analysis we took as SF network: sf5.l3, as ER network: er5.l2 as real \n",
    "network: eu_transportation.KLM. We chose layers by smallest num of connected \n",
    "componenets, smallest density, and longest diameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc import net_loader\n",
    "networks = [\n",
    "  \"aucs\",\n",
    "  \"ckm_physicians\",\n",
    "  \"eu_transportation\",\n",
    "  \"eu_trans_1\",\n",
    "  \"lazega\",\n",
    "  \"er1\",\n",
    "  \"er2\",\n",
    "  \"er3\",\n",
    "  \"er5\",\n",
    "  \"sf1\",\n",
    "  \"sf2\",\n",
    "  \"sf3\",\n",
    "  \"sf5\",\n",
    "]\n",
    "nets = [(n, net_loader.load_network(n)) for n in networks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "\n",
    "for (net_name, net) in nets:\n",
    "    for l_name, l_graph in net.layers.items():\n",
    "        cc = len(list(nx.connected_components(l_graph)))\n",
    "        if cc > 1:\n",
    "            dd = None\n",
    "        else:\n",
    "            dd = nx.diameter(l_graph)\n",
    "        df_list.append(\n",
    "            {\n",
    "                \"net_name\": net_name,\n",
    "                \"l_name\": l_name,\n",
    "                \"connected_components\": cc,\n",
    "                \"nodes\": len(l_graph.nodes()),\n",
    "                \"edges\": len(l_graph.edges()),\n",
    "                \"diameter\": dd,\n",
    "                \"density\": nx.density(l_graph)\n",
    "            }\n",
    "        )\n",
    "\n",
    "df = pd.DataFrame(df_list)\n",
    "df.to_csv(\"net_stats.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ltm-seeding-mln",
   "language": "python",
   "name": "ltm-seeding-mln"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
