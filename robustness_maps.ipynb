{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute robustness maps for evaluated methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"experiments/all_results.csv\")\n",
    "df = df.drop(\"Unnamed: 0\", axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_methods = df[\"selection_metric\"].unique()\n",
    "protocols = df[\"protocol\"].unique()\n",
    "\n",
    "# in some experiments mi_value was saved tih too big precision (differences \n",
    "# in 15th floating place) hence we need to round them \n",
    "df[\"mi_value\"] = df[\"mi_value\"].round(1)\n",
    "mi_vals = df[\"mi_value\"].unique()\n",
    "\n",
    "# permute networks so that they're ordered as following:\n",
    "# - real networks, ER SF\n",
    "nets_ml = [\n",
    "    'aucs', 'ckm_physicians', 'eu_transportation', 'lazega', \n",
    "    'er2', 'er3', 'er5', 'sf2', 'sf3', 'sf5',\n",
    "]\n",
    "nets_sl = [\"eu_trans_1\", \"er1\", \"sf1\"]\n",
    "assert set(df[\"network\"].unique()) == set(nets_ml + nets_sl)\n",
    "\n",
    "\n",
    "#\n",
    "#\n",
    "_net_choice = \"ml\"  # <----------- SELECT network type to analyse\n",
    "#\n",
    "#\n",
    "\n",
    "if _net_choice == \"ml\":\n",
    "    nets = nets_ml\n",
    "    net_case = \"multilayer\"\n",
    "elif _net_choice == \"sl\":\n",
    "    nets = nets_sl\n",
    "    net_case = \"singlelayer\"\n",
    "elif _net_choice == \"all\":\n",
    "    nets = nets_ml + nets_sl\n",
    "    net_case = \"all\" \n",
    "else:\n",
    "    raise ValueError\n",
    "print(f\"Choice: {net_case}\")\n",
    "\n",
    "ss_methods_abbrv_map ={\n",
    "    'degree_centrality': \"deg-c\",\n",
    "    'greedy': \"greedy\",\n",
    "    'k_shell': \"k-sh\",\n",
    "    'k_shell_mln': \"k-sh-m\",\n",
    "    'neighbourhood_size': \"nghb-1s\",\n",
    "    'neighbourhood_2_hop_size': \"nghb-2s\",\n",
    "    'page_rank': \"p-rnk\",\n",
    "    'page_rank_mln': \"p-rnk-m\",\n",
    "    'random': \"random\",\n",
    "    'vote_rank': \"v-rnk\",\n",
    "    'vote_rank_mln': \"v-rnk-m\",\n",
    "}\n",
    "\n",
    "nets_abbrv_map = {\n",
    "    \"aucs\": \"aucs\",\n",
    "    \"ckm_physicians\": \"ckmp\",\n",
    "    \"lazega\": \"lazega\",\n",
    "    \"eu_transportation\": \"eutr-A\",\n",
    "    \"eu_trans_1\": \"eutr-1\",\n",
    "    \"er1\": \"er-1\",\n",
    "    \"er2\": \"er-2\",\n",
    "    \"er3\": \"er-3\",\n",
    "    \"er5\": \"er-5\",\n",
    "    \"sf1\": \"sf-1\",\n",
    "    \"sf2\": \"sf-2\",\n",
    "    \"sf3\": \"sf-3\",\n",
    "    \"sf5\": \"sf-5\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for protocol OR we had budgets like [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25, 30] \n",
    "# for protocol AND we had budgets like \n",
    "# [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40],\n",
    "# but we'd like to skip wery low budgets where all methods are unaccurate and keep only:\n",
    "# [15, 20, 25, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40] \n",
    "rows_to_drop = df.loc[\n",
    "    (df[\"protocol\"] == \"AND\") & \n",
    "    (\n",
    "        ~df[\"seeding_budget\"].isin(\n",
    "            {15, 20, 25, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40}\n",
    "        )\n",
    "    )\n",
    "]\n",
    "df = df.drop(rows_to_drop.index)\n",
    "s_budgets = df[\"seeding_budget\"].unique()\n",
    "\n",
    "# drop unselected nets\n",
    "rows_to_drop = df.loc[~df[\"network\"].isin(set(nets))]\n",
    "df = df.drop(rows_to_drop.index)\n",
    "\n",
    "\n",
    "ss_methods, protocols, mi_vals, s_budgets, nets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert data to a multidimensional matrices for each network type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "proto = \"AND\"  # <---------- change this to plot stats for AND!!!\n",
    "#\n",
    "#\n",
    "\n",
    "s_budgets_proto = df.loc[df[\"protocol\"] == proto][\"seeding_budget\"].unique()\n",
    "cube = {}\n",
    "consist_shape = []\n",
    "\n",
    "for ssm in ss_methods:\n",
    "    for net in nets:\n",
    "        ddf = df.loc[\n",
    "            (df[\"network\"] == net) &\n",
    "            (df[\"protocol\"] == proto) &\n",
    "            (df[\"selection_metric\"] == ssm)\n",
    "        ]\n",
    "        ddf = pd.pivot_table(\n",
    "            ddf, index=\"mi_value\", columns=\"seeding_budget\", values=\"gain\"\n",
    "        ).to_numpy()\n",
    "        if len(consist_shape) == 0:\n",
    "            consist_shape = ddf.shape\n",
    "        if len(ddf) == 0:\n",
    "            ddf = np.empty(shape=consist_shape)\n",
    "            ddf[:] = np.nan\n",
    "\n",
    "        if not cube.get(ssm):\n",
    "            cube[ssm] = {}\n",
    "        cube[ssm][net] = ddf\n",
    "\n",
    "len(cube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_arrays = []\n",
    "ssm_axis = []\n",
    "nets_axis = []\n",
    "\n",
    "for ssm, net_dict in cube.items(): \n",
    "    ssm_axis.append(ssm)\n",
    "    _arrs = []\n",
    "    for idx, (net, arr) in enumerate(net_dict.items()):\n",
    "        if len(nets_axis) == len(nets):\n",
    "            assert nets_axis[idx] == net\n",
    "        else:\n",
    "            nets_axis.append(net)\n",
    "        _arrs.append(arr)\n",
    "\n",
    "    list_arrays.append(np.stack(_arrs))\n",
    "\n",
    "cube_gain = np.stack(list_arrays)\n",
    "nets_axis = np.array([nets_abbrv_map[nname] for nname in nets_axis])\n",
    "\n",
    "# array with all gains concatenated for all test runs - check shape (L==R)\n",
    "cube_gain.shape, (len(ss_methods), len(nets), len(mi_vals), len(s_budgets_proto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to manually obtain indices of real, sf and er nets\n",
    "print(nets_axis)\n",
    "\n",
    "rn_names = nets_axis[rn_idx := [0, 1, 2, 3]]\n",
    "er_names = nets_axis[en_idx := [4, 5, 6]]\n",
    "sf_names = nets_axis[sn_idx := [7, 8, 9]]\n",
    "\n",
    "print(rn_names)\n",
    "print(er_names)\n",
    "print(sf_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gains_real_nets = cube_gain[:, rn_idx, ...]\n",
    "gains_er_nets = cube_gain[:, en_idx, ...]\n",
    "gains_sf_nets = cube_gain[:, sn_idx, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take mean value across all network types\n",
    "gains_real_mean = np.mean(gains_real_nets, 1)\n",
    "gains_er_mean = np.mean(gains_er_nets, 1)\n",
    "gains_sf_mean = np.mean(gains_sf_nets, 1)\n",
    "gains_all_mean = np.mean(cube_gain, 1)\n",
    "\n",
    "gains_real_nets = np.append(gains_real_nets, gains_real_mean[:, np.newaxis, ...], axis=1)\n",
    "gains_er_nets = np.append(gains_er_nets, gains_er_mean[:, np.newaxis, ...], axis=1)\n",
    "gains_sf_nets = np.append(gains_sf_nets, gains_sf_mean[:, np.newaxis, ...], axis=1)\n",
    "\n",
    "rn_names = np.append(rn_names, \"mean-real\")\n",
    "er_names = np.append(er_names, \"mean-er\")\n",
    "sf_names = np.append(sf_names, \"mean-sf\")\n",
    "\n",
    "# now we have in each array values of gain for each ssm, network, mi, sb enhanced by a slice ssm, mean_network, mi, sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or take only averaged performance pre network type\n",
    "gains_mean = np.array([gains_real_mean, gains_er_mean, gains_sf_mean, gains_all_mean]).transpose([1, 0, 2, 3])\n",
    "avg_names = [\"mean-real\", \"mean-er\", \"mean-sf\", \"mean-all\"]\n",
    "\n",
    "gains_mean.shape, avg_names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create robustness maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(arr: np.ndarray, mi_ax: int, sb_ax: int) -> np.ndarray:\n",
    "    arr_dmi = np.gradient(arr, axis=mi_ax)\n",
    "    arr_dsb = np.gradient(arr, axis=sb_ax)\n",
    "    arr_dmi_dsb = (np.sqrt((arr_dmi ** 2) + (arr_dsb ** 2)))[:, ::-1, :]\n",
    "    return arr_dmi_dsb\n",
    "\n",
    "\n",
    "def obtain_robust_idxs(arr: np.ndarray) -> List[Tuple[int, int]]:\n",
    "    \"\"\"Arr is a boolean matrix, output are coords.\"\"\"\n",
    "    robust_border_idxs = []\n",
    "    for sb_idx, mi_tab in enumerate(arr.T):\n",
    "        # print(mi_tab[::-1])\n",
    "        for mi_idx, mi in enumerate(mi_tab[::-1]):\n",
    "            if mi == True:\n",
    "                robust_border_idxs.append([sb_idx, mi_idx])\n",
    "                break\n",
    "    return robust_border_idxs\n",
    "\n",
    "\n",
    "def obtain_unrobust_idxs(arr: np.ndarray) -> List[Tuple[int, int]]:\n",
    "    \"\"\"Arr is a boolean matrix, output are coords.\"\"\"\n",
    "    unrobust_border_idxs = []\n",
    "    for sb_idx, mi_tab in enumerate(arr.T):\n",
    "        for mi_idx, mi in enumerate(mi_tab):\n",
    "            if mi == True:\n",
    "                unrobust_border_idxs.append([sb_idx, len(mi_tab) - 1 - mi_idx])\n",
    "                break\n",
    "    return unrobust_border_idxs\n",
    "\n",
    "\n",
    "def convert_idxs(border_idxs: List[Tuple[int, int]]) -> np.ndarray:\n",
    "    robust_border_coords = [\n",
    "        [s_budgets_proto[sb_idx], mi_vals[mi_idx]] for \n",
    "        sb_idx, mi_idx in border_idxs\n",
    "    ]\n",
    "    robust_border_coords = np.array(robust_border_coords)\n",
    "    return robust_border_coords\n",
    "\n",
    "\n",
    "def obtain_robust_curve(arr: np.ndarray) -> np.ndarray:\n",
    "    return convert_idxs(obtain_robust_idxs(arr))\n",
    "\n",
    "\n",
    "def obtain_unrobust_curve(arr: np.ndarray) -> np.ndarray:\n",
    "    return convert_idxs(obtain_unrobust_idxs(arr))\n",
    "\n",
    "\n",
    "def log_func(x, a, b):\n",
    "    return a * np.log(x) + b\n",
    "\n",
    "\n",
    "def polynomial_3rd(x, a, b, c, d):\n",
    "    return a * x ** 3 + b * x ** 2 + c * x + d\n",
    "\n",
    "\n",
    "def sigmoid(x, a, b):\n",
    "    return a * (np.exp(x) / (np.exp(x) + 1)) + b\n",
    "\n",
    "\n",
    "def exp_func(x, a, b):\n",
    "    return a * np.exp(x) + b\n",
    "\n",
    "\n",
    "def optimize(func, curve_x, curve_y):\n",
    "    parameters, covariance = curve_fit(func, curve_x, curve_y)\n",
    "    std_err = np.sqrt(np.diag(covariance))\n",
    "    fit_func = func(curve_x, *parameters)\n",
    "    return (fit_func,\n",
    "            {idx: val for idx, val in enumerate(std_err)},\n",
    "            {idx: val for idx, val in enumerate(parameters)},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rn_names)\n",
    "print(er_names)\n",
    "print(sf_names)\n",
    "print(avg_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysed_arr = gains_er_nets  # <---- select array to analyse\n",
    "analysed_names = er_names  # <---- select proper names of nets\n",
    "analysed_net = \"mean-er\"  # <---- select network to analyse\n",
    "\n",
    "idx = int(np.where(np.array(analysed_names) == analysed_net)[0])\n",
    "\n",
    "func = log_func  # <---- select function to aproximate curves with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = analysed_arr[:, idx, ...]\n",
    "print(arr.shape)\n",
    "\n",
    "out_dir = Path(\"data/findings/robustness_maps\")\n",
    "out_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "vis_name = out_dir / f\"map_proto-{proto}_net-{analysed_net}.png\"\n",
    "fit_err_name = out_dir / f\"err_proto-{proto}_net-{analysed_net}.csv\"\n",
    "fit_par_name = out_dir / f\"fit_proto-{proto}_net-{analysed_net}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_arr = grad(arr, mi_ax=-2, sb_ax=-1)\n",
    "\n",
    "curves = {}\n",
    "\n",
    "for idx, ssm_grad in enumerate(grad_arr):\n",
    "\n",
    "    method = ss_methods_abbrv_map[ss_methods[idx]]\n",
    "\n",
    "    # sns.heatmap(ssm_grad, xticklabels=s_budgets_proto, yticklabels=mi_vals[::-1], cbar=False)\n",
    "    # plt.title(f\"raw gradinent for {method}\")\n",
    "    # plt.tight_layout()\n",
    "    # plt.savefig(out_dir / f\"raw_grad_{method}.png\")\n",
    "    # plt.close()\n",
    "\n",
    "    ssm_grad = ssm_grad > 10\n",
    "\n",
    "    # sns.heatmap(ssm_grad, xticklabels=s_budgets_proto, yticklabels=mi_vals[::-1], cbar=False)\n",
    "    # plt.title(f\"thresholded gradinent for {method}\")\n",
    "    # plt.tight_layout()\n",
    "    # plt.savefig(out_dir / f\"thre_grad_{method}.png\")\n",
    "    # plt.close()\n",
    "\n",
    "    curves[method] = {\n",
    "        \"robust\": obtain_robust_curve(ssm_grad),\n",
    "        \"unrobust\": obtain_unrobust_curve(ssm_grad)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a particular visualisation on curve fitting\n",
    "\n",
    "# method  = \"v-rnk-m\"\n",
    "\n",
    "# grad_robust = curves[method][\"robust\"]\n",
    "# grad_unrobust = curves[method][\"unrobust\"]\n",
    "\n",
    "# pts = np.linspace(1, max(s_budgets_proto))  \n",
    "\n",
    "# fit_func_robust, std_err_robust, par_robust = optimize(log_func, grad_robust[:, 0], grad_robust[:, 1])\n",
    "# fit_func_robust = log_func(pts, *par_robust.values())\n",
    "\n",
    "# fit_func_unrobust, std_err_unrobust, par_unrobust = optimize(log_func, grad_unrobust[:, 0], grad_unrobust[:, 1])\n",
    "# fit_func_unrobust = log_func(pts, *par_unrobust.values()) \n",
    "\n",
    "# plt.ylim(min(mi_vals), max(mi_vals))\n",
    "# plt.xlim(min(pts), max(pts))\n",
    "\n",
    "# plt.fill_between(pts, fit_func_robust, alpha=.5, color=\"green\")\n",
    "# plt.fill_between(pts, fit_func_unrobust, max(mi_vals) * len(fit_func_unrobust), alpha=.5, color=\"red\")\n",
    "# plt.fill_between(pts, fit_func_unrobust, fit_func_robust, alpha=.5, color=\"orange\")\n",
    "\n",
    "# plt.title(f\"map for {method}\")\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(out_dir / f\"map_{method}.png\")\n",
    "# plt.close()\n",
    "\n",
    "# print(\"Robust coeff: \", par_robust, \"std_err:\", std_err_robust)\n",
    "# print(\"Unobust coeff: \", par_unrobust, \"std_err:\", std_err_unrobust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_iter = iter(plt.cm.jet(np.linspace(0, 1, len(curves))))\n",
    "line_width = 2\n",
    "\n",
    "fit_errors = {}\n",
    "fit_params = {}\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "\n",
    "for idx, (ssm, curve) in enumerate(curves.items()):\n",
    "    \n",
    "    pts_robust = curve[\"robust\"]\n",
    "    pts_unrobust = curve[\"unrobust\"]\n",
    "\n",
    "    try:\n",
    "        fit_func_robust, std_err_robust, par_robust = optimize(func, pts_robust[:, 0], pts_robust[:, 1])\n",
    "        fit_func_unrobust, std_err_unrobust, par_unrobust = optimize(func, pts_unrobust[:, 0], pts_unrobust[:, 1])\n",
    "\n",
    "        # if fitted function is too short - expand it to be plotted on entire canvas\n",
    "        if len(fit_func_robust) < len(s_budgets):\n",
    "            fit_func_robust = func(s_budgets, *par_robust.values())\n",
    "        if len(fit_func_unrobust) < len(s_budgets):\n",
    "            fit_func_unrobust = func(s_budgets, *par_unrobust.values()) \n",
    "        pts = s_budgets           \n",
    "\n",
    "    except BaseException as e:\n",
    "        if ssm != \"greedy\":\n",
    "            raise e\n",
    "        continue\n",
    "\n",
    "    fit_errors[(ssm, \"robust\")] = std_err_robust\n",
    "    fit_errors[(ssm, \"unrobust\")] = std_err_unrobust\n",
    "    fit_params[(ssm, \"robust\")] = par_robust\n",
    "    fit_params[(ssm, \"unrobust\")] = par_unrobust\n",
    "\n",
    "    color = next(color_iter)\n",
    "    alpha = .8\n",
    "    linestyle=(4 * random.random(), (2, 2))\n",
    "\n",
    "    if ssm == \"random\":\n",
    "        ax.fill_between(\n",
    "            pts, fit_func_robust, alpha=.5, color=\"green\", \n",
    "        )\n",
    "    elif ssm == \"greedy\":\n",
    "        try:\n",
    "            ax.fill_between(\n",
    "                pts,\n",
    "                fit_func_unrobust,\n",
    "                max(mi_vals) * len(fit_func_unrobust),\n",
    "                alpha=.5,\n",
    "                color=\"red\",\n",
    "            )\n",
    "        except BaseException as e:\n",
    "            pass\n",
    "    else:\n",
    "        plt.plot(\n",
    "            pts,\n",
    "            fit_func_robust,\n",
    "            label=ssm,\n",
    "            marker='',\n",
    "            color=color,\n",
    "            linewidth=line_width,\n",
    "            linestyle=linestyle,\n",
    "            alpha=alpha,\n",
    "        )\n",
    "\n",
    "ax.set_xlim(min(s_budgets_proto), max(s_budgets_proto))\n",
    "# ax.set_xscale(\"log\")\n",
    "ax.set_xticks(s_budgets_proto)\n",
    "ax.get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "ax.set_ylim(min(mi_vals), max(mi_vals))\n",
    "ax.legend(loc=\"upper left\")\n",
    "ax.grid()\n",
    "# fig.suptitle(vis_name.stem)\n",
    "fig.set_size_inches(6, 5)\n",
    "fig.tight_layout()\n",
    "fig.savefig(vis_name, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(fit_errors).T.to_csv(fit_err_name)\n",
    "pd.DataFrame(fit_params).T.to_csv(fit_par_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute avg error of curve fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errs = {}\n",
    "\n",
    "for err in out_dir.glob(\"[err]*.csv\"):\n",
    "    print(err)\n",
    "    raw_err_df = pd.read_csv(\n",
    "        err,\n",
    "        names=[\n",
    "            \"ssm\",\n",
    "            \"curve\",\n",
    "            \"parameter_0\",\n",
    "            \"parameter_1\",\n",
    "            # \"parameter_2\",\n",
    "            # \"parameter_3\"\n",
    "        ],\n",
    "        header=1\n",
    "    )\n",
    "    unrobust_to_drop = raw_err_df.loc[(raw_err_df[\"curve\"] == \"unrobust\") & (raw_err_df[\"ssm\"] != \"greedy\")].index\n",
    "    robust_to_drop = raw_err_df.loc[(raw_err_df[\"curve\"] == \"robust\") & (raw_err_df[\"ssm\"] == \"greedy\")].index\n",
    "    err_df = raw_err_df.drop(unrobust_to_drop, axis=0).drop(robust_to_drop, axis=0)\n",
    "\n",
    "    errs[err.stem[4:]] = err_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars = {}\n",
    "\n",
    "for par in out_dir.glob(\"[fit]*.csv\"):\n",
    "    print(par)\n",
    "    raw_par_df = pd.read_csv(\n",
    "        par,\n",
    "        names=[\n",
    "            \"ssm\",\n",
    "            \"curve\",\n",
    "            \"parameter_0\",\n",
    "            \"parameter_1\",\n",
    "            # \"parameter_2\",\n",
    "            # \"parameter_3\"\n",
    "        ],\n",
    "        header=1\n",
    "    )\n",
    "    \n",
    "    unrobust_to_drop = raw_par_df.loc[(raw_par_df[\"curve\"] == \"unrobust\") & (raw_par_df[\"ssm\"] != \"greedy\")].index\n",
    "    robust_to_drop = raw_par_df.loc[(raw_par_df[\"curve\"] == \"robust\") & (raw_par_df[\"ssm\"] == \"greedy\")].index\n",
    "    par_df = raw_par_df.drop(unrobust_to_drop, axis=0).drop(robust_to_drop, axis=0)\n",
    "\n",
    "    pars[par.stem[4:]] = par_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_errs_prct = {}\n",
    "\n",
    "for figure_name, par_df in pars.items():\n",
    "    err_df = errs[figure_name]\n",
    "\n",
    "    _ = pd.merge(err_df, par_df, on=[\"ssm\", \"curve\"], suffixes=[\"_err\", \"_par\"])\n",
    "    _[\"parameter_0_prct_err\"] = np.abs(100 * _[\"parameter_0_err\"] / _[\"parameter_0_par\"])\n",
    "    _[\"parameter_1_prct_err\"] = np.abs(100 * _[\"parameter_1_err\"] / _[\"parameter_1_par\"])\n",
    "    # _[\"parameter_2_prct_err\"] = np.abs(100 * _[\"parameter_2_err\"] / _[\"parameter_2_par\"])\n",
    "    # _[\"parameter_3_prct_err\"] = np.abs(100 * _[\"parameter_3_err\"] / _[\"parameter_3_par\"])\n",
    "\n",
    "    mean_errs_prct[figure_name] = {\n",
    "        \"parameter_0_prct_err\": _[\"parameter_0_prct_err\"].mean(),\n",
    "        \"parameter_1_prct_err\": _[\"parameter_1_prct_err\"].mean(),\n",
    "        # \"parameter_2_prct_err\": _[\"parameter_2_prct_err\"].mean(),\n",
    "        # \"parameter_3_prct_err\": _[\"parameter_3_prct_err\"].mean(),\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_errs_prct_df = pd.DataFrame(mean_errs_prct).T\n",
    "mean_errs_prct_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_errs_prct_df.to_csv(out_dir / \"mean_errors.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ltm-seeding-mln",
   "language": "python",
   "name": "ltm-seeding-mln"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
