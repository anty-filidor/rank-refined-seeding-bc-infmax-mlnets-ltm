{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute effectiveness maps for evaluated methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"_experiments/top_methods/all_results.csv\")\n",
    "df = df.drop(\"Unnamed: 0\", axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_methods = df[\"selection_metric\"].unique()\n",
    "protocols = sorted(df[\"protocol\"].unique(), reverse=True)  # this is only to keep the order: OR and AND\n",
    "\n",
    "# in some experiments mi_value was saved tih too big precision (differences \n",
    "# in 15th floating place) hence we need to round them \n",
    "df[\"mi_value\"] = df[\"mi_value\"].round(1)\n",
    "mi_vals = df[\"mi_value\"].unique()\n",
    "\n",
    "# permute networks so that they're ordered as following:\n",
    "nets = [\"arxiv\", \"timik1q2009\"]\n",
    "assert set(df[\"network\"].unique()) == set(nets)\n",
    "\n",
    "# set up a path where results are saved in\n",
    "workdir = Path(\"_results\")\n",
    "workdir.mkdir(exist_ok=True)\n",
    "\n",
    "ss_methods_abbrv_map ={\n",
    "    \"cbim\": \"cbim\",\n",
    "    \"cim\": \"cim\",\n",
    "    'degree_centrality': \"deg-c\",\n",
    "    'degree_centrality_discount': \"deg-c-d\",\n",
    "    'greedy': \"greedy\",\n",
    "    'k_shell': \"k-sh\",\n",
    "    'k_shell_mln': \"k-sh-m\",\n",
    "    'kpp_shell': \"kpp-sh\",\n",
    "    'neighbourhood_size': \"nghb-1s\",\n",
    "    'neighbourhood_2_hop_size': \"nghb-2s\",\n",
    "    'neighbourhood_size_discount': \"nghb-sd\",\n",
    "    'page_rank': \"p-rnk\",\n",
    "    'page_rank_mln': \"p-rnk-m\",\n",
    "    'random': \"random\",\n",
    "    'vote_rank': \"v-rnk\",\n",
    "    'vote_rank_mln': \"v-rnk-m\",\n",
    "}\n",
    "\n",
    "nets_abbrv_map = {\n",
    "    \"arxiv\": \"arxiv\",\n",
    "    \"timik1q2009\": \"timik\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for protocol OR we had budgets like [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25, 30] \n",
    "# for protocol AND we had budgets like \n",
    "# [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40],\n",
    "# but we'd like to skip wery low budgets where all methods are unaccurate and keep only:\n",
    "# [15, 20, 25, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40] \n",
    "rows_to_drop = df.loc[\n",
    "    (df[\"protocol\"] == \"AND\") & \n",
    "    (\n",
    "        ~df[\"seeding_budget\"].isin(\n",
    "            {15, 20, 25, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40}\n",
    "        )\n",
    "    )\n",
    "]\n",
    "df = df.drop(rows_to_drop.index)\n",
    "\n",
    "s_budgets = df[\"seeding_budget\"].unique()\n",
    "s_budgets_proto = {\n",
    "    \"OR\": df.loc[df[\"protocol\"] == \"OR\"][\"seeding_budget\"].unique(),\n",
    "    \"AND\": df.loc[df[\"protocol\"] == \"AND\"][\"seeding_budget\"].unique()\n",
    "}\n",
    "assert set(s_budgets) == set(s_budgets_proto[\"OR\"]).union(set(s_budgets_proto[\"AND\"]))\n",
    "\n",
    "# drop unselected nets\n",
    "rows_to_drop = df.loc[~df[\"network\"].isin(set(nets))]\n",
    "df = df.drop(rows_to_drop.index)\n",
    "\n",
    "\n",
    "ss_methods, protocols, mi_vals, s_budgets, nets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert data to a multidimensional matrices of obtained Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube = {}\n",
    "\n",
    "for ssm in ss_methods:\n",
    "    for net in nets:\n",
    "        for proto in protocols:\n",
    "            ddf = df.loc[\n",
    "                (df[\"network\"] == net) &\n",
    "                (df[\"protocol\"] == proto) &\n",
    "                (df[\"selection_metric\"] == ssm)\n",
    "            ]\n",
    "            ddf = pd.pivot_table(ddf, index=\"mi_value\", columns=\"seeding_budget\", values=\"gain\").to_numpy()\n",
    "            if len(ddf) == 0:\n",
    "                raise ArithmeticError(f\"Incorrect form of the dataframe for: {ssm}, {net}, {proto}\")\n",
    "            if not cube.get(ssm):\n",
    "                cube[ssm] = {}\n",
    "            if not cube[ssm].get(net):\n",
    "                cube[ssm][net] = {}\n",
    "            cube[ssm][net][proto] = ddf\n",
    "\n",
    "len(cube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssm_axis = []\n",
    "nets_axis = []\n",
    "protocols_axis = []\n",
    "\n",
    "ssm_arrays = []\n",
    "\n",
    "for ssm, net_proto_dict in cube.items():\n",
    "    # print(ssm)\n",
    "    ssm_axis.append(ssm)\n",
    "    net_arrays = []\n",
    "\n",
    "    for idx, (net, proto_dict) in enumerate(net_proto_dict.items()):\n",
    "        # print(net)\n",
    "        if len(nets_axis) == len(nets):\n",
    "            assert nets_axis[idx] == net\n",
    "        else:\n",
    "            nets_axis.append(net)\n",
    "        proto_arrs = []\n",
    "\n",
    "        for idx, (proto, arr) in enumerate(proto_dict.items()):\n",
    "            # print(proto)\n",
    "            if len(protocols_axis) == len(protocols):\n",
    "                assert protocols_axis[idx] == proto\n",
    "            else:\n",
    "                protocols_axis.append(proto)\n",
    "\n",
    "            proto_arrs.append(arr)\n",
    "        \n",
    "        net_arrays.append(np.stack(proto_arrs))\n",
    "\n",
    "    ssm_arrays.append(np.stack(net_arrays))\n",
    "\n",
    "cube_gain = np.stack(ssm_arrays)\n",
    "\n",
    "# array with all gains concatenated for all test runs - check shape (L==R)\n",
    "cube_gain.shape, (len(ss_methods), len(nets), len(protocols), len(mi_vals), len(s_budgets_proto[\"AND\"]))  # can be OR as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to manually obtain indices of networks\n",
    "print(nets_axis)\n",
    "\n",
    "arxiv_idx = 0\n",
    "timik1q2009_idx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gains_arxiv = cube_gain[:, arxiv_idx, ...]\n",
    "gains_timik1q2009 = cube_gain[:, timik1q2009_idx, ...]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create effectiveness maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(arr: np.ndarray, mi_ax: int, sb_ax: int) -> np.ndarray:\n",
    "    arr_dmi = np.gradient(arr, axis=mi_ax)\n",
    "    arr_dsb = np.gradient(arr, axis=sb_ax)\n",
    "    arr_dmi_dsb = (np.sqrt((arr_dmi ** 2) + (arr_dsb ** 2)))[:, :, ::-1, :]\n",
    "    return arr_dmi_dsb\n",
    "\n",
    "\n",
    "def obtain_robust_idxs(arr: np.ndarray) -> List[Tuple[int, int]]:\n",
    "    \"\"\"Arr is a boolean matrix, output are coords.\"\"\"\n",
    "    robust_border_idxs = []\n",
    "    for sb_idx, mi_tab in enumerate(arr.T):\n",
    "        # print(mi_tab[::-1])\n",
    "        for mi_idx, mi in enumerate(mi_tab[::-1]):\n",
    "            if mi == True:\n",
    "                robust_border_idxs.append([sb_idx, mi_idx])\n",
    "                break\n",
    "    return robust_border_idxs\n",
    "\n",
    "\n",
    "def obtain_unrobust_idxs(arr: np.ndarray) -> List[Tuple[int, int]]:\n",
    "    \"\"\"Arr is a boolean matrix, output are coords.\"\"\"\n",
    "    unrobust_border_idxs = []\n",
    "    for sb_idx, mi_tab in enumerate(arr.T):\n",
    "        for mi_idx, mi in enumerate(mi_tab):\n",
    "            if mi == True:\n",
    "                unrobust_border_idxs.append([sb_idx, len(mi_tab) - 1 - mi_idx])\n",
    "                break\n",
    "    return unrobust_border_idxs\n",
    "\n",
    "\n",
    "def convert_idxs(\n",
    "        border_idxs: List[Tuple[int, int]], s_budgets_list: List[int]\n",
    "    ) -> np.ndarray:\n",
    "    robust_border_coords = [\n",
    "        [s_budgets_list[sb_idx], mi_vals[mi_idx]] for \n",
    "        sb_idx, mi_idx in border_idxs\n",
    "    ]\n",
    "    robust_border_coords = np.array(robust_border_coords)\n",
    "    return robust_border_coords\n",
    "\n",
    "\n",
    "def obtain_robust_curve(arr: np.ndarray, s_budgets_list: List[int]) -> np.ndarray:\n",
    "    return convert_idxs(obtain_robust_idxs(arr), s_budgets_list)\n",
    "\n",
    "\n",
    "def obtain_unrobust_curve(arr: np.ndarray, s_budgets_list: List[int]) -> np.ndarray:\n",
    "    return convert_idxs(obtain_unrobust_idxs(arr), s_budgets_list)\n",
    "\n",
    "\n",
    "def log_func(x, a, b):\n",
    "    return a * np.log(x) + b\n",
    "\n",
    "\n",
    "def polynomial_3rd(x, a, b, c, d):\n",
    "    return a * x ** 3 + b * x ** 2 + c * x + d\n",
    "\n",
    "\n",
    "def sigmoid(x, a, b):\n",
    "    return a * (np.exp(x) / (np.exp(x) + 1)) + b\n",
    "\n",
    "\n",
    "def exp_func(x, a, b):\n",
    "    return a * np.exp(x) + b\n",
    "\n",
    "\n",
    "def optimize(func, curve_x, curve_y):\n",
    "    parameters, covariance = curve_fit(func, curve_x, curve_y)\n",
    "    std_err = np.sqrt(np.diag(covariance))\n",
    "    fit_func = func(curve_x, *parameters)\n",
    "    return (fit_func,\n",
    "            {idx: val for idx, val in enumerate(std_err)},\n",
    "            {idx: val for idx, val in enumerate(parameters)},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select arxiv network\n",
    "analysed_arr = gains_arxiv\n",
    "analysed_net = nets[arxiv_idx]\n",
    "\n",
    "# # or timik\n",
    "# analysed_arr = gains_timik1q2009\n",
    "# analysed_net = nets[timik1q2009_idx]\n",
    "\n",
    "# select function to aproximate curves with\n",
    "func = log_func\n",
    "\n",
    "print(analysed_net, analysed_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = Path(\"_results/top_efficiency_maps\")\n",
    "out_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "vis_name = out_dir / f\"map_net-{analysed_net}.pdf\"\n",
    "fit_err_name = out_dir / f\"params-err_net-{analysed_net}.csv\"\n",
    "fit_par_name = out_dir / f\"params-fit_net-{analysed_net}.csv\"\n",
    "fit_bulk_err_name = out_dir / f\"params-err-avg_net-{analysed_net}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_arr = grad(analysed_arr, mi_ax=-2, sb_ax=-1)\n",
    "\n",
    "curves = {}\n",
    "\n",
    "for idx, ssm_proto_grad in enumerate(grad_arr):\n",
    "    method = ss_methods_abbrv_map[ss_methods[idx]]\n",
    "    # print(method, ssm_proto_grad.shape)\n",
    "\n",
    "    protos = {}\n",
    "\n",
    "    for iidx, proto_grad in enumerate(ssm_proto_grad):\n",
    "        proto = protocols[iidx]\n",
    "        # print(proto, proto_grad.shape)\n",
    "\n",
    "        # sns.heatmap(\n",
    "        #     proto_grad,\n",
    "        #     xticklabels=s_budgets_proto[proto],\n",
    "        #     yticklabels=mi_vals[::-1],\n",
    "        #     cbar=False,\n",
    "        #     annot=True,\n",
    "        #     annot_kws={\"size\": 7},\n",
    "        # )\n",
    "        # plt.title(f\"raw gradinent for {method} and {proto}\")\n",
    "        # plt.tight_layout()\n",
    "        # plt.savefig(out_dir / f\"grad_{method}_{proto}_raw.pdf\")\n",
    "        # plt.close()\n",
    "\n",
    "        proto_grad = proto_grad > 10\n",
    "\n",
    "        # sns.heatmap(\n",
    "        #     proto_grad,\n",
    "        #     xticklabels=s_budgets_proto[proto],\n",
    "        #     yticklabels=mi_vals[::-1],\n",
    "        #     cbar=False,\n",
    "        #     annot=True,\n",
    "        #     annot_kws={\"size\": 7},\n",
    "        # )\n",
    "        # plt.title(f\"thresholded gradinent for {method} and {proto}\")\n",
    "        # plt.tight_layout()\n",
    "        # plt.savefig(out_dir / f\"grad_{method}_{proto}_thre.pdf\")\n",
    "        # plt.close()\n",
    "\n",
    "        protos[proto] = {\n",
    "            \"effective\": obtain_robust_curve(proto_grad, s_budgets_proto[proto]),\n",
    "            \"ineffective\": obtain_unrobust_curve(proto_grad, s_budgets_proto[proto])\n",
    "        }\n",
    "\n",
    "    curves[method] = protos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a particular visualisation on curve fitting\n",
    "\n",
    "_method  = \"v-rnk-m\"\n",
    "_proto = \"OR\"\n",
    "\n",
    "\n",
    "grad_robust = curves[_method][_proto][\"effective\"]\n",
    "grad_unrobust = curves[_method][_proto][\"ineffective\"]\n",
    "\n",
    "pts = np.linspace(1, max(s_budgets_proto[\"OR\"]))\n",
    "\n",
    "fit_func_robust, std_err_robust, par_robust = optimize(log_func, grad_robust[:, 0], grad_robust[:, 1])\n",
    "fit_func_robust = log_func(pts, *par_robust.values())\n",
    "\n",
    "fit_func_unrobust, std_err_unrobust, par_unrobust = optimize(log_func, grad_unrobust[:, 0], grad_unrobust[:, 1])\n",
    "fit_func_unrobust = log_func(pts, *par_unrobust.values()) \n",
    "\n",
    "plt.ylim(min(mi_vals), max(mi_vals))\n",
    "plt.xlim(min(pts), max(pts))\n",
    "\n",
    "plt.fill_between(pts, fit_func_robust, alpha=.5, color=\"green\")\n",
    "plt.fill_between(pts, fit_func_unrobust, max(mi_vals) * len(fit_func_unrobust), alpha=.5, color=\"red\")\n",
    "plt.fill_between(pts, fit_func_unrobust, fit_func_robust, alpha=.5, color=\"orange\")\n",
    "\n",
    "plt.title(f\"map for {_method} with {_proto} on {analysed_net}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# plt.savefig(out_dir / f\"map_{_method}.png\")\n",
    "# plt.close()\n",
    "\n",
    "print(\"Robust coeff: \", par_robust, \"std_err:\", std_err_robust)\n",
    "print(\"Unobust coeff: \", par_unrobust, \"std_err:\", std_err_unrobust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_iter = iter(plt.cm.jet(np.linspace(0, 1, len(ss_methods))))\n",
    "colors_ssm = {ss_methods_abbrv_map[ssm]: next(color_iter) for ssm in ss_methods}\n",
    "line_width = 1.5\n",
    "\n",
    "fit_errors = {}\n",
    "fit_params = {}\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 4), gridspec_kw={\"width_ratios\": [50, 50]})\n",
    "fig.tight_layout(rect=(0.05, 0.05, 0.95, 0.95))\n",
    "title = f\"Efficiency curves on {analysed_net}; protocols from left: {protocols[0]}, {protocols[1]}\"\n",
    "\n",
    "\n",
    "for ssm, proto_curves in curves.items():\n",
    "    # print(ssm)\n",
    "\n",
    "    for proto, curve in proto_curves.items():\n",
    "        # print(proto)\n",
    "\n",
    "        pts_robust = curve[\"effective\"]\n",
    "        pts_unrobust = curve[\"ineffective\"]\n",
    "        s_budgets_pts = np.linspace(1, max(s_budgets_proto[proto]))\n",
    "\n",
    "        fit_func_robust, std_err_robust, par_robust = optimize(func, pts_robust[:, 0], pts_robust[:, 1])\n",
    "        fit_func_robust = func(s_budgets_pts, *par_robust.values())\n",
    "\n",
    "        fit_func_unrobust, std_err_unrobust, par_unrobust = optimize(func, pts_unrobust[:, 0], pts_unrobust[:, 1])\n",
    "        fit_func_unrobust = func(s_budgets_pts, *par_unrobust.values())\n",
    "\n",
    "        fit_errors[(ssm, proto, \"effective\")] = std_err_robust\n",
    "        fit_errors[(ssm, proto, \"ineffective\")] = std_err_unrobust\n",
    "        fit_params[(ssm, proto, \"effective\")] = par_robust\n",
    "        fit_params[(ssm, proto, \"ineffective\")] = par_unrobust\n",
    "\n",
    "        idx = protocols.index(proto)\n",
    "        linestyle=(4 * random.random(), (4, 1))\n",
    "        ax[idx].plot(\n",
    "            s_budgets_pts,\n",
    "            fit_func_robust,\n",
    "            label=ssm,\n",
    "            marker='',\n",
    "            color=colors_ssm[ssm],\n",
    "            linewidth=line_width,\n",
    "            linestyle=linestyle,\n",
    "            alpha=.75,\n",
    "        )\n",
    "\n",
    "for axx, proto in zip(ax, protocols):\n",
    "    axx.tick_params(axis='both', which='major', labelsize=8)\n",
    "    axx.set_xlim(min(s_budgets_proto[proto]), max(s_budgets_proto[proto]))\n",
    "    axx.set_xticks(s_budgets_proto[proto])\n",
    "    axx.set_ylim(min(mi_vals), max(mi_vals))\n",
    "    axx.legend(loc=\"lower right\")\n",
    "    axx.grid()\n",
    "    axx.set_xlabel(\"seeding_budget\")\n",
    "    axx.set_ylabel(\"mi_value\")\n",
    "\n",
    "fig.suptitle(title)\n",
    "fig.savefig(vis_name, dpi=300)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_errors_df = pd.DataFrame(fit_errors).T\n",
    "fit_errors_df.index.names = [\"method\", \"protocol\", \"curve_type\"]\n",
    "# fit_errors_df.to_csv(fit_err_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params_df = pd.DataFrame(fit_params).T\n",
    "fit_params_df.index.names = [\"method\", \"protocol\", \"curve_type\"]\n",
    "# fit_params_df.to_csv(fit_par_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute avg error of curve fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_fit_errors_df = fit_errors_df.reset_index()\n",
    "unrobust_to_drop = _fit_errors_df.loc[(_fit_errors_df[\"curve_type\"] == \"ineffective\")].index\n",
    "_fit_errors_df = _fit_errors_df.drop(unrobust_to_drop, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_fit_params_df = fit_params_df.reset_index()\n",
    "unrobust_to_drop = _fit_params_df.loc[(_fit_params_df[\"curve_type\"] == \"ineffective\")].index\n",
    "_fit_params_df = _fit_params_df.drop(unrobust_to_drop, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params_errors_df = pd.merge(_fit_errors_df, _fit_params_df, on=[\"method\", \"curve_type\", \"protocol\"], suffixes=[\"_err\", \"_par\"])\n",
    "fit_params_errors_df[\"0_prct_err\"] = np.abs(100 * fit_params_errors_df[\"0_err\"] / fit_params_errors_df[\"0_par\"])\n",
    "fit_params_errors_df[\"1_prct_err\"] = np.abs(100 * fit_params_errors_df[\"1_err\"] / fit_params_errors_df[\"1_par\"])\n",
    "# fit_params_errors_df[\"2_prct_err\"] = np.abs(100 * fit_params_errors_df[\"2_err\"] / fit_params_errors_df[\"2_par\"])\n",
    "# fit_params_errors_df[\"3_prct_err\"] = np.abs(100 * fit_params_errors_df[\"3_err\"] / fit_params_errors_df[\"3_par\"])\n",
    "fit_params_errors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_prct_err_df = fit_params_errors_df[[\"0_prct_err\", \"1_prct_err\", \"protocol\"]].groupby(\"protocol\").mean()\n",
    "# mean_prct_err_df = fit_params_errors_df[[\"0_prct_err\", \"1_prct_err\", \"2_prct_err\", \"3_prct_err\", \"protocol\"]].groupby(\"protocol\").mean()\n",
    "mean_prct_err_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params_errors_df.to_csv(fit_par_name)\n",
    "mean_prct_err_df.to_csv(fit_bulk_err_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ltm-seeding-mln",
   "language": "python",
   "name": "ltm-seeding-mln"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
